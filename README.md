%%markdown
# 1. Определение задачи Named Entity Recognition (NER)

**Что такое NER?**  
Named Entity Recognition (NER) — это одна из базовых задач обработки естественного языка (NLP), цель которой — найти в тексте упоминания конкретных объектов (сущностей) и определить их тип. В нашем проекте мы работаем с русскоязычными новостями про Brexit и выделяем пять категорий:

- **PER** (Person) — имена и фамилии людей (например, «Тереза Мэй», «Борис Джонсон»).  
- **ORG** (Organization) — названия организаций и компаний (например, «Конференция партии тори», «Европейская комиссия»).  
- **LOC** (Location) — географические объекты и места (например, «Лондон», «Альбион»).  
- **EVT** (Event) — события и процедуры (например, «конференция», «процедура Brexit»).  
- **PRO** (Product) — продукты, услуги, документы (например, «доклад», «соглашение»).

В результате мы либо получаем список триплетов `(begin_index, end_index, label)`, либо посл-токен+метку в формате BIO (B‑начало, I‑внутри, O‑вне сущности).

---

## Классические подходы

1. **Rule‑based / шаблонные методы**  
   - Словари (gazetteers): предопределённые списки имён, организаций, городов.  
   - Регулярные выражения: шаблоны для дат, чисел, заглавных букв.  
   - **Плюсы:** высокая точность в узкой доменной области, понятность.  
   - **Минусы:** трудоёмкость поддержки, низкая обобщаемость.

2. **Статистические модели**  
   - **HMM (Hidden Markov Model):** скрытые состояния — метки сущностей, наблюдаемые — слова/токены.  
   - **CRF (Conditional Random Fields):** графовая модель, учитывает зависимости между соседними метками и позволяет вводить богатые признаки:
     - **Лексические:** само слово, лемма, суффиксы/префиксы.  
     - **Синтаксические:** POS‑теги, синтаксические зависимости.  
     - **Контекстные:** соседние слова и метки.

3. **Классификация токенов**  
   - Например, SVM или логистическая регрессия на вручную созданных признаках (n‑граммы, позиция в предложении, заглавные буквы).
   - **Ограничение:** сложность ручного создания качественных признаков.

---

## Подходы на основе LLM

1. **Prompt‑based NER**  
   - Zero‑shot/few‑shot: даём в промпте пример размеченного фрагмента и просим модель повторить на новом тексте.  
   - **Пример промпта:**
     ```
     В тексте выделены сущности:
     [PER: Тереза Мэй], [ORG: Конференция партии тори], [LOC: Лондон]
     Текст: «…»
     Дай список сущностей в формате JSON: [{"text":"...","type":"...","start":...,"end":...}, …]
     ```

2. **Token‑classification API**  
   - Если API модели поддерживает обработку токенов с выдачей BIO‑меток напрямую.

3. **Chain‑of‑Thought**  
   - Сначала просим найти все кандидаты на сущности (без типа), затем отдельным запросом — классифицировать каждый фрагмент.

4. **Fine‑tuning**  
   - Дообучение модели на размеченных данных (ограничено доступностью API и объёмом разметки).

---

## Метрики оценки качества

- **Precision (точность):** TP / (TP + FP)  
- **Recall (полнота):** TP / (TP + FN)  
- **F1‑score:** 2 · (Precision · Recall) / (Precision + Recall)

**Типы совпадений:**  
- **Strict** — полное совпадение границ и типа сущности.  
- **Partial** — допускается частичное наложение или несовпадение границ.

**Усреднение:**  
- **Micro‑F1** — объединяем все примеры и считаем глобальную F1.  
- **Macro‑F1** — считаем F1 отдельно для каждого типа сущности и усредняем.

> Дальше переходим к практической части: чтение данных, генерация промптов, сбор ответов и вычисление метрик.
